name: Update Package Repositories

on:
  workflow_call:
    inputs:
      artifact_pattern:
        type: string
        default: 'pkg-*'
        description: 'Pattern to download build artifacts'
      source_distro:
        type: string
        default: 'noble'
        description: 'Codename of the source distro the packages were built on'
      device:
        type: string
        required: true
        description: 'Device ID from devices.yml (e.g. l4t). Used for repo paths and dependency prefix'
    secrets:
      GPG_PRIVATE_KEY:
        required: true

permissions:
  contents: write

jobs:
  # ==================================================================
  # NORMALIZE: Extract all packages to intermediate format (parallel)
  # ==================================================================
  normalize:
    runs-on: ubuntu-24.04
    outputs:
      arches: ${{ steps.normalize.outputs.arches }}
      count: ${{ steps.normalize.outputs.count }}
      matrix: ${{ steps.normalize.outputs.matrix }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: main

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: ${{ inputs.artifact_pattern }}
          merge-multiple: true

      - name: Check for packages
        id: check
        run: |
          HAS_PKGS=false
          ls *.pkg.tar 1>/dev/null 2>&1 && HAS_PKGS=true
          ls *.deb 1>/dev/null 2>&1 && HAS_PKGS=true
          ls *.rpm 1>/dev/null 2>&1 && HAS_PKGS=true
          ls *.pkg.tar.zst 1>/dev/null 2>&1 && HAS_PKGS=true
          ls *.pkg.tar.xz 1>/dev/null 2>&1 && HAS_PKGS=true

          echo "has_pkgs=$HAS_PKGS" >> $GITHUB_OUTPUT
          if [[ "$HAS_PKGS" == "true" ]]; then
            echo "=== Downloaded packages ==="
            ls -la *.pkg.tar *.deb *.rpm *.pkg.tar.zst *.pkg.tar.xz 2>/dev/null || true
          else
            echo "No packages to publish"
          fi

      - name: Install tools
        if: steps.check.outputs.has_pkgs == 'true'
        run: sudo apt-get update && sudo apt-get install -y dpkg-dev rpm libarchive-tools zstd

      - name: Normalize all packages
        if: steps.check.outputs.has_pkgs == 'true'
        id: normalize
        run: |
          chmod +x scripts/pkg-extract.sh scripts/pkg-build-deb.sh scripts/pkg-build-rpm.sh scripts/pkg-build-pacman.sh scripts/resolve-deps.sh

          SOURCE_DISTRO="${{ inputs.source_distro }}"
          SCRIPT_DIR="$(pwd)/scripts"
          MAX_PARALLEL=12
          mkdir -p intermediates

          PKG_INDEX=0

          # 1) .pkg.tar = already intermediate, just extract (sequential — fast)
          for f in *.pkg.tar; do
            [[ -f "$f" ]] || continue
            INTDIR="intermediates/pkg-${PKG_INDEX}"
            mkdir -p "$INTDIR"
            tar xf "$f" -C "$INTDIR"
            echo "  [INT] $(cat "$INTDIR/meta/name") from $f"
            PKG_INDEX=$((PKG_INDEX + 1))
          done

          # 2) All other formats — parallel extraction
          for f in *.deb *.rpm *.pkg.tar.zst *.pkg.tar.xz; do
            [[ -f "$f" ]] || continue
            INTDIR="intermediates/pkg-${PKG_INDEX}"
            PKG_INDEX=$((PKG_INDEX + 1))
            "$SCRIPT_DIR/pkg-extract.sh" "$f" "$INTDIR" --source-distro "$SOURCE_DISTRO" &
            while [[ $(jobs -rp | wc -l) -ge $MAX_PARALLEL ]]; do wait -n; done
          done
          wait

          echo "=== Normalized $PKG_INDEX packages ==="

          # Detect architectures
          ARCHES=""
          for intdir in intermediates/pkg-*; do
            [[ -d "$intdir/meta" ]] || continue
            A=$(cat "$intdir/meta/arch")
            ARCHES="$ARCHES $A"
          done
          ARCHES=$(echo "$ARCHES" | tr ' ' '\n' | sort -u | grep -v '^$' | tr '\n' ' ')
          echo "arches=$ARCHES" >> $GITHUB_OUTPUT
          echo "Detected architectures: $ARCHES"
          echo "count=$PKG_INDEX" >> $GITHUB_OUTPUT

          # Generate own-packages skip list
          for intdir in intermediates/pkg-*; do
            [[ -d "$intdir/meta" ]] || continue
            cat "$intdir/meta/name"
          done | sort -u > own-packages.txt
          echo "Own packages ($(wc -l < own-packages.txt) entries):"
          cat own-packages.txt

          # Generate matrix from distros.yml
          MATRIX="["
          for id in $(yq -r '.distros.apt[].id' distros.yml); do
            is_source=$([[ "$id" == "$SOURCE_DISTRO" ]] && echo true || echo false)
            MATRIX+="{\"distro\":\"$id\",\"format\":\"deb\",\"is_source\":$is_source},"
          done
          for id in $(yq -r '.distros.dnf[].id' distros.yml); do
            version=$(yq -r ".distros.dnf[] | select(.id == \"$id\") | .version" distros.yml)
            MATRIX+="{\"distro\":\"$id\",\"format\":\"rpm\",\"is_source\":false,\"version\":\"$version\"},"
          done
          for id in $(yq -r '.distros.pacman[].id' distros.yml); do
            MATRIX+="{\"distro\":\"$id\",\"format\":\"pacman\",\"is_source\":false},"
          done
          MATRIX="${MATRIX%,}]"
          echo "matrix=$MATRIX" >> $GITHUB_OUTPUT
          echo "Matrix: $MATRIX"

      - name: Upload intermediates
        if: steps.check.outputs.has_pkgs == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: intermediates-${{ inputs.device }}
          path: |
            intermediates/
            own-packages.txt
            scripts/
            distros.yml
            pages/
            README.md
          retention-days: 1

  # ==================================================================
  # BUILD-REPO: One job per distro (matrix), parallel internal builds
  # ==================================================================
  build-repo:
    needs: normalize
    if: needs.normalize.outputs.count > 0
    runs-on: ubuntu-24.04
    strategy:
      fail-fast: false
      matrix:
        include: ${{ fromJson(needs.normalize.outputs.matrix) }}
    steps:
      - name: Download intermediates
        uses: actions/download-artifact@v4
        with:
          name: intermediates-${{ inputs.device }}

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
        with:
          platforms: arm64,arm

      - name: Install tools
        run: |
          sudo apt-get update
          sudo apt-get install -y dpkg-dev apt-utils rpm createrepo-c libarchive-tools zstd
          chmod +x scripts/pkg-extract.sh scripts/pkg-build-deb.sh scripts/pkg-build-rpm.sh scripts/pkg-build-pacman.sh scripts/resolve-deps.sh

      - name: Build ${{ matrix.format }} repo for ${{ matrix.distro }}
        run: |
          SCRIPT_DIR="$(pwd)/scripts"
          DEP_MAP="$SCRIPT_DIR/dep-map.conf"
          SOURCE_DISTRO="${{ inputs.source_distro }}"
          DEVICE="${{ inputs.device }}"
          DISTRO="${{ matrix.distro }}"
          FORMAT="${{ matrix.format }}"
          IS_SOURCE="${{ matrix.is_source }}"
          MAX_PARALLEL=8

          echo "=== Building $FORMAT repo for $DISTRO ==="

          # Determine build script
          case "$FORMAT" in
            deb)    BUILD_SCRIPT="$SCRIPT_DIR/pkg-build-deb.sh" ;;
            rpm)    BUILD_SCRIPT="$SCRIPT_DIR/pkg-build-rpm.sh" ;;
            pacman) BUILD_SCRIPT="$SCRIPT_DIR/pkg-build-pacman.sh" ;;
          esac

          # Map arch for directory names
          map_dir_arch() {
            local arch="$1"
            case "$FORMAT" in
              deb)
                case "$arch" in
                  aarch64) echo "arm64" ;;
                  x86_64)  echo "amd64" ;;
                  armhf)   echo "armhf" ;;
                  *)       echo "$arch" ;;
                esac ;;
              rpm)
                case "$arch" in
                  aarch64) echo "aarch64" ;;
                  x86_64)  echo "x86_64" ;;
                  armhf)   echo "armv7hl" ;;
                  *)       echo "$arch" ;;
                esac ;;
              pacman)
                case "$arch" in
                  aarch64) echo "aarch64" ;;
                  x86_64)  echo "x86_64" ;;
                  armhf)   echo "armv7h" ;;
                  *)       echo "$arch" ;;
                esac ;;
            esac
          }

          # Create output structure
          mkdir -p repo-output

          for arch in ${{ needs.normalize.outputs.arches }}; do
            DIR_ARCH=$(map_dir_arch "$arch")
            echo ""
            echo "--- $DISTRO / $DIR_ARCH ($arch) ---"

            # Create format-specific output dirs (per-device repos)
            case "$FORMAT" in
              deb)
                POOL_DIR="repo-output/apt/${DEVICE}/pool/${DISTRO}"
                mkdir -p "$POOL_DIR"
                mkdir -p "repo-output/apt/${DEVICE}/dists/${DISTRO}/main/binary-${DIR_ARCH}"
                OUTPUT_DIR="$POOL_DIR"
                ;;
              rpm)
                VERSION="${{ matrix.version }}"
                OUTPUT_DIR="repo-output/dnf/${DEVICE}/${VERSION}/${DIR_ARCH}"
                mkdir -p "$OUTPUT_DIR"
                ;;
              pacman)
                OUTPUT_DIR="repo-output/pacman/${DEVICE}/${DIR_ARCH}"
                mkdir -p "$OUTPUT_DIR"
                ;;
            esac

            if [[ "$IS_SOURCE" == "true" ]]; then
              # Source distro: build directly, no dep resolution
              echo "Building packages (source distro, no dep resolution)..."
              for intdir in intermediates/pkg-*; do
                [[ -d "$intdir/meta" ]] || continue
                [[ "$(cat "$intdir/meta/arch")" == "$arch" ]] || continue
                (
                  TMPOUT=$(mktemp -d)
                  if "$BUILD_SCRIPT" "$intdir" "$TMPOUT/" --dep-map "$DEP_MAP" 2>&1; then
                    cp "$TMPOUT"/* "$OUTPUT_DIR/" 2>/dev/null || true
                  else
                    echo "WARNING: Failed to build from $(basename "$intdir")"
                  fi
                  rm -rf "$TMPOUT"
                ) &
                while [[ $(jobs -rp | wc -l) -ge $MAX_PARALLEL ]]; do wait -n; done
              done
              wait
            else
              # Non-source distro: build temp → resolve deps → rebuild with mapping

              # Step 1: Build temp packages for dep scanning (parallel)
              echo "Step 1: Building temp packages for dep scanning..."
              TEMP_DIR=$(mktemp -d)
              for intdir in intermediates/pkg-*; do
                [[ -d "$intdir/meta" ]] || continue
                [[ "$(cat "$intdir/meta/arch")" == "$arch" ]] || continue
                (
                  TMPOUT=$(mktemp -d)
                  if "$BUILD_SCRIPT" "$intdir" "$TMPOUT/" --dep-map "$DEP_MAP" 2>/dev/null; then
                    cp "$TMPOUT"/* "$TEMP_DIR/" 2>/dev/null || true
                  fi
                  rm -rf "$TMPOUT"
                ) &
                while [[ $(jobs -rp | wc -l) -ge $MAX_PARALLEL ]]; do wait -n; done
              done
              wait

              # Step 2: Resolve deps (batch fetch + parallel rebuild)
              echo "Step 2: Resolving dependencies..."
              FETCH_DIR="fetched-deps-${DISTRO}-${arch}"
              mkdir -p "$FETCH_DIR"
              PREFIX_ARG=""
              [[ -n "$DEVICE" ]] && PREFIX_ARG="--prefix $DEVICE"
              "$SCRIPT_DIR/resolve-deps.sh" \
                --source-pkgs "$TEMP_DIR" \
                --source-distro "$SOURCE_DISTRO" \
                --target-distro "$DISTRO" \
                --target-format "$FORMAT" \
                --distros-config distros.yml \
                --dep-map "$DEP_MAP" \
                --output-dir "$FETCH_DIR" \
                --arch "$arch" \
                --skip-names own-packages.txt \
                $PREFIX_ARG || echo "WARNING: dep resolution had errors for $DISTRO"

              # Step 3: Copy prefixed dep packages to output
              case "$FORMAT" in
                deb)    for f in "$FETCH_DIR"/*.deb;         do [[ -f "$f" ]] && cp "$f" "$OUTPUT_DIR/"; done ;;
                rpm)    for f in "$FETCH_DIR"/*.rpm;         do [[ -f "$f" ]] && cp "$f" "$OUTPUT_DIR/"; done ;;
                pacman) for f in "$FETCH_DIR"/*.pkg.tar.zst; do [[ -f "$f" ]] && cp "$f" "$OUTPUT_DIR/"; done ;;
              esac

              # Step 4: Rebuild our packages with mapping applied (parallel)
              echo "Step 4: Rebuilding packages with dependency mapping..."
              MAPPING="$FETCH_DIR/dep-mapping.txt"
              for intdir in intermediates/pkg-*; do
                [[ -d "$intdir/meta" ]] || continue
                [[ "$(cat "$intdir/meta/arch")" == "$arch" ]] || continue
                (
                  INTCOPY=$(mktemp -d)
                  cp -a "$intdir"/* "$INTCOPY/"

                  if [[ -s "$MAPPING" ]]; then
                    while IFS='=' read -r orig prefixed; do
                      [[ -z "$orig" ]] && continue
                      sed -i "s/^${orig}$/${prefixed}/" "$INTCOPY/meta/depends" 2>/dev/null || true
                    done < "$MAPPING"
                  fi

                  TMPOUT=$(mktemp -d)
                  if "$BUILD_SCRIPT" "$INTCOPY" "$TMPOUT/" --dep-map "$DEP_MAP" 2>&1; then
                    cp "$TMPOUT"/* "$OUTPUT_DIR/" 2>/dev/null || true
                  else
                    echo "WARNING: Failed to rebuild $(cat "$INTCOPY/meta/name" 2>/dev/null) for $DISTRO"
                  fi
                  rm -rf "$INTCOPY" "$TMPOUT"
                ) &
                while [[ $(jobs -rp | wc -l) -ge $MAX_PARALLEL ]]; do wait -n; done
              done
              wait

              rm -rf "$TEMP_DIR"
            fi
          done

          # Generate repo metadata
          echo ""
          echo "=== Generating repo metadata ==="
          case "$FORMAT" in
            deb)
              for arch in ${{ needs.normalize.outputs.arches }}; do
                DIR_ARCH=$(map_dir_arch "$arch")
                cd "repo-output/apt/${DEVICE}"
                mkdir -p "dists/${DISTRO}/main/binary-${DIR_ARCH}"
                dpkg-scanpackages --arch "$DIR_ARCH" "pool/${DISTRO}" > "dists/${DISTRO}/main/binary-${DIR_ARCH}/Packages" 2>/dev/null || true
                gzip -k -f "dists/${DISTRO}/main/binary-${DIR_ARCH}/Packages"
                cd ../../..
              done
              ;;
            rpm)
              VERSION="${{ matrix.version }}"
              for arch in ${{ needs.normalize.outputs.arches }}; do
                DIR_ARCH=$(map_dir_arch "$arch")
                RPM_DIR="repo-output/dnf/${DEVICE}/${VERSION}/${DIR_ARCH}"
                if ls "$RPM_DIR"/*.rpm 1>/dev/null 2>&1; then
                  createrepo_c "$RPM_DIR/"
                fi
              done
              ;;
            pacman)
              for arch in ${{ needs.normalize.outputs.arches }}; do
                DIR_ARCH=$(map_dir_arch "$arch")
                PAC_DIR="repo-output/pacman/${DEVICE}/${DIR_ARCH}"
                if ls "$PAC_DIR"/*.pkg.tar.zst 1>/dev/null 2>&1; then
                  docker run --rm -v "$(pwd)/$PAC_DIR:/repo" archlinux:latest \
                    bash -c "cd /repo && repo-add astralemu.db.tar.gz *.pkg.tar.zst"
                fi
              done
              ;;
          esac

          echo "=== Done building $FORMAT repo for $DISTRO ==="

      - name: Upload repo artifact
        uses: actions/upload-artifact@v4
        with:
          name: repo-${{ inputs.device }}-${{ matrix.distro }}
          path: repo-output/
          retention-days: 1

  # ==================================================================
  # DEPLOY: Merge all repo artifacts and push to gh-pages
  # ==================================================================
  deploy:
    needs: [normalize, build-repo]
    if: always() && needs.normalize.outputs.count > 0
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: main

      - name: Download intermediates (for pages template)
        uses: actions/download-artifact@v4
        with:
          name: intermediates-${{ inputs.device }}
          path: intermediates-data/

      - name: Download all repo artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: repo-${{ inputs.device }}-*
          path: repo-artifacts/

      - name: Install tools
        run: sudo apt-get update && sudo apt-get install -y pandoc apt-utils

      - name: Import GPG key
        run: echo "${{ secrets.GPG_PRIVATE_KEY }}" | gpg --batch --import

      - name: Checkout gh-pages
        run: |
          git fetch origin gh-pages:gh-pages || true
          git worktree add gh-pages-dir gh-pages || {
            git worktree add --detach gh-pages-dir
            cd gh-pages-dir
            git checkout --orphan gh-pages
            git rm -rf . 2>/dev/null || true
            cd ..
          }
          DEVICE="${{ inputs.device }}"
          mkdir -p "gh-pages-dir/apt/${DEVICE}" "gh-pages-dir/dnf/${DEVICE}" "gh-pages-dir/pacman/${DEVICE}"

      - name: Merge repo artifacts
        run: |
          for repo_dir in repo-artifacts/repo-*/; do
            [[ -d "$repo_dir" ]] || continue
            echo "Merging: $repo_dir"
            cp -a "$repo_dir"/* gh-pages-dir/ 2>/dev/null || true
          done
          echo "=== Merged structure ==="
          find gh-pages-dir -type f | head -50

      - name: Sign APT releases
        run: |
          DEVICE="${{ inputs.device }}"

          # Export GPG public key
          gpg --armor --export "AstralEmu Packages" > "gh-pages-dir/apt/${DEVICE}/astralemu.gpg"

          # Sign Release for each APT distro
          APT_IDS=$(yq -r '.distros.apt[].id' distros.yml)
          for distro_id in $APT_IDS; do
            DIST_DIR="gh-pages-dir/apt/${DEVICE}/dists/${distro_id}"
            [[ -d "$DIST_DIR" ]] || continue

            cd "$DIST_DIR"
            ARCH_LIST=$(ls -d main/binary-* 2>/dev/null | sed 's|main/binary-||' | tr '\n' ' ')

            cat > Release << RELEASE_EOF
          Origin: AstralEmu Packages (${DEVICE})
          Label: astralemu-${DEVICE}
          Suite: ${distro_id}
          Codename: ${distro_id}
          Architectures: ${ARCH_LIST}
          Components: main
          Description: AstralEmu ${DEVICE} packages for ${distro_id}
          RELEASE_EOF

            apt-ftparchive release . >> Release
            rm -f Release.gpg InRelease
            gpg --batch --default-key "AstralEmu Packages" -abs -o Release.gpg Release
            gpg --batch --default-key "AstralEmu Packages" --clearsign -o InRelease Release
            cd ../../../../..
          done

      - name: Sign DNF repos
        run: |
          DEVICE="${{ inputs.device }}"

          gpg --armor --export "AstralEmu Packages" > "gh-pages-dir/dnf/${DEVICE}/astralemu.gpg"

          # Sign repomd.xml for each DNF repo
          find "gh-pages-dir/dnf/${DEVICE}" -name 'repomd.xml' | while read -r repomd; do
            rm -f "${repomd}.asc"
            gpg --batch --default-key "AstralEmu Packages" -abs \
              -o "${repomd}.asc" "$repomd"
          done

          # Create .repo config
          cat > "gh-pages-dir/dnf/${DEVICE}/astralemu-${DEVICE}.repo" << REPO_EOF
          [astralemu-${DEVICE}]
          name=AstralEmu Packages (${DEVICE})
          baseurl=https://astralemu.github.io/astralemu-packages/dnf/${DEVICE}/\$releasever/\$basearch/
          enabled=1
          gpgcheck=1
          gpgkey=https://astralemu.github.io/astralemu-packages/dnf/${DEVICE}/astralemu.gpg
          REPO_EOF

      - name: Generate landing page
        run: |
          if [[ -f intermediates-data/pages/template.html ]]; then
            pandoc README.md --from gfm --to html5 \
              --template intermediates-data/pages/template.html \
              --metadata title="AstralEmu Packages" \
              -o gh-pages-dir/index.html
          fi

      - name: Remove oversized files
        run: |
          MAX_MB=95
          find gh-pages-dir -type f -size +${MAX_MB}M | while read -r f; do
            echo "Removing oversized file: $f ($(du -h "$f" | cut -f1))"
            rm -f "$f"
          done

      - name: Deploy to gh-pages
        run: |
          cd gh-pages-dir
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          git commit -m "Update package repositories" || echo "No changes"
          git push origin gh-pages
